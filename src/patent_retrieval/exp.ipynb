{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SamOz.py\\OneDrive\\Documents\\VSCode\\datenna\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from engine import PatentRetrievalService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 149/149 [02:01<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "service = PatentRetrievalService('../data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"enzymes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced mode\n",
    "results = service.retrieve_patents(keywords, precision_recall_balance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'keywords': ['enzymes'],\n",
       "  'total_matches': 4703,\n",
       "  'precision_recall_balance': 0.991,\n",
       "  'embedding_model': 'paraphrase-multilingual-MiniLM-L12-v2'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "model_name = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "dataset_path = '../data.txt'\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        abstracts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 149/149 [02:02<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_model.encode(sentences=abstracts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product index for cosine similarity\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = [\"enzymes\", \"medical\"]\n",
    "# keyword_embeddings = embedding_model.encode(keyword)\n",
    "keyword_embedding = embedding_model.encode([' '.join(keywords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_keyword_embeddings = np.mean(keyword_embeddings, axis=0).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(pooled_keyword_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = index.search(pooled_keyword_embeddings, k=len(abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.48743364)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_balance = 0.001\n",
    "threshold = np.percentile(\n",
    "            distances, \n",
    "            (1 - precision_recall_balance) * 100\n",
    "        )\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2734,  392, 3571, 2270, 2204])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_indices = indices[distances >= threshold]\n",
    "relevant_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5001985 ,  0.4993974 ,  0.49889547, ..., -0.10678346,\n",
       "        -0.10801981, -0.13303286]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.10021333)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[0][2734]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изобретение относится к области биотехнологии, конкретно, к фармацевтической композиции и способу профилактики и лечения недостаточности лизосомального фермента у субъекта, что может быть использовано в медицине. Настоящее изобретение относится к соединению HIR-Fab-IDS, применяемому для профилактики или лечения недостаточности лизосомального фермента у субъекта, имеющего лизосомную болезнь накопления, представляющую собой мукополисахаридоз II типа, где субъекту вводят по меньшей мере одну дозу соединения HIR-Fab-IDS от 1 до 12 мг/кг, к фармацевтической композиции для применения для профилактики или лечения недостаточности лизосомального фермента у субъекта, имеющей лизосомную болезнь накопления, представляющую собой мукополисахаридоз II типа, где композиция содержит соединение HIR-Fab-IDS, а также к способу профилактики или лечения недостаточности лизосомального фермента у субъекта, имеющего лизосомную болезнь накопления, представляющую собой мукополисахаридоз II типа, включающий введение пациенту по меньшей мере одной дозы соединения HIR-Fab-IDS.\n",
      "A presente invenção refere-se a hidrazidas bloqueadoras de Nav 1.7 e/ou Nav 1.8. Mais especificamente, a presente invenção relata hidrazidas que compreendem a Fórmula (I):(I) em que os substituintes R1 a R8 são selecionados independentemente dos grupos definidos no relatório descritivo, bem como seus processos de obtenção, composições compreendendo pelo menos um destes compostos, usos, métodos de tratamento para tratar ou prevenir patologias relacionadas à dor e kits. A presente invenção encontra-se nos campos da química medicinal, síntese orgânica, bem como no tratamento de doenças relacionadas com a dor.\n",
      "A presente invenção refere-se a hidroxamatos bloqueadores de Nav 1.7 e/ou Nav 1.8. Mais especificamente, a presente invenção relata hidroxamatos que compreendem a Fórmula (I), em que os substituintes R1 a R10, assim como seus derivados R11 a R20, são selecionados independentemente dos grupos definidos no relatório descritivo, bem como seus processos de obtenção, composições compreendendo pelo menos um destes compostos, usos, métodos de tratamento para tratar ou prevenir patologias relacionadas à dor e kits. A presente invenção encontra-se nos campos da química medicinal, síntese orgânica, bem como no tratamento de doenças relacionadas com a dor.\n",
      "De huidige uitvinding heeft betrekking op een gehydrolyseerde collageenformulering voor gebruik bij het verlagen van bloedglucose. Het gehydrolyseerde collageen wordt verkregen door enzymatische hydrolyse van een collageen bevattend materiaal met een combinatie van enzymen die twee of meer enzymen omvat, gekozen uit de groep bestaande uit een neutrale protease, een carboxypeptidase en een aminopeptidase. De gehydrolyseerde collageenformulering is in het bijzonder geschikt als voedingssupplement, zoals voor gebruik bij het verlichten van hyperglykemie en/of een risicofactor hyperglykemie.\n",
      "Described herein is a new method for treating diseases such as non-alcoholic fatty liver  disease and non-alcoholic steatohepatitis with a growth hormone secretagogue alone or in  combination with a drug selected from a dipeptidyl peptidase-4 antagonist, a glucagon-like  peptide receptor agonist, a thiazolidinedione, a sodium glucose transport protein 2 antagonist,  and metformin. Compositions relating to the same are also provided.   13186639_1 (GHMatters) P113941.AU\n"
     ]
    }
   ],
   "source": [
    "for idx in relevant_indices:\n",
    "    print(abstracts[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'abstract' : [],\n",
    "        'relevance_score': [],\n",
    "        }\n",
    "for i, idx in enumerate(relevant_indices):\n",
    "    results['abstract'].append(abstracts[idx])\n",
    "    results['relevance_score'].append(distances[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation = _generate_explanation(2734, keyword, 0.001)\n",
    "type(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def _generate_explanation(\n",
    "        abstract_idx: int,\n",
    "        keywords: List[str],\n",
    "        precision_recall_balance: float\n",
    "    ) -> str:\n",
    "        \"\"\"Generate an explanation for why an abstract is relevant\"\"\"\n",
    "        abstract = abstracts[abstract_idx]\n",
    "        \n",
    "        # Find keyword matches\n",
    "        keyword_matches = [\n",
    "            kw for kw in keywords \n",
    "            if kw.lower() in abstract.lower()\n",
    "        ]\n",
    "        \n",
    "        # Compute semantic similarity\n",
    "        keyword_embedding = embedding_model.encode(keywords)\n",
    "        abstract_embedding = embeddings[abstract_idx]\n",
    "        semantic_similarities = [\n",
    "            float(np.dot(keyword_emb, abstract_embedding)) \n",
    "            for keyword_emb in keyword_embedding\n",
    "        ]\n",
    "        \n",
    "        # Add precision-recall context to explanation\n",
    "        precision_context = (\n",
    "            \"high precision mode - focusing on closest matches\"\n",
    "            if precision_recall_balance > 0.7\n",
    "            else \"balanced precision-recall\"\n",
    "            if 0.3 <= precision_recall_balance <= 0.7\n",
    "            else \"high recall mode - including broader matches\"\n",
    "        )\n",
    "        \n",
    "        explanation = {\n",
    "            \"Match Analysis\": precision_context,\n",
    "            \"Direct keyword matches\": len(keyword_matches),\n",
    "            \"Semantic similarity score\": np.mean(semantic_similarities)\n",
    "            \"Matched keywords\": \"\".join(keyword_matches) if keyword_matches else None\n",
    "        }\n",
    "        return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
